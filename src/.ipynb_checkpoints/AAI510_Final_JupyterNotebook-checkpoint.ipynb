{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New York City AirBnB Data Modeling and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Made for the University of San Diego\n",
    "Course: AAI-510 (Machine learning: Fundamentals and Applications)\n",
    "Professor: Wesley Pasfield, MS\n",
    "\n",
    "By - Doug Code (dcode15), Subhabrata Ganguli (suvoganguli), Jeffrey Lehrer (J-Lehrer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f28gG-djkTS"
   },
   "source": [
    "# Problem statement and justification for the proposed approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqniy4ov2GGS"
   },
   "source": [
    "Business understanding - What does the business need?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqniy4ov2GGS"
   },
   "source": [
    "## [Modify/Delete as necessary]\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Airbnb, an online marketplace for lodging, has transformed the way people travel and find accommodations. In major cities like New York City, Airbnb listings provide a wide variety of options for travelers, ranging from entire apartments and homes to private rooms in shared apartments. This flexibility has made Airbnb a popular choice among both tourists and business travelers.\n",
    "\n",
    "In this notebook, we will explore the Airbnb dataset for New York City. This dataset provides detailed information on listings available on Airbnb, including prices, locations, types of properties, and reviews. By analyzing this data, we can gain insights into the rental market in New York City, understand pricing strategies, identify popular neighborhoods, and much more.\n",
    "\n",
    "## Dataset Description\n",
    "\n",
    "The dataset used in this analysis is obtained from [Inside Airbnb](http://insideairbnb.com/get-the-data.html), a website that provides publicly available data on Airbnb listings. The New York City dataset contains various attributes for each listing, including:\n",
    "\n",
    "- **Listing ID**: A unique identifier for each Airbnb listing.\n",
    "- **Name**: The name of the listing.\n",
    "- **Host ID**: A unique identifier for the host.\n",
    "- **Host Name**: The name of the host.\n",
    "- **Neighborhood Group**: The general area or borough where the listing is located (e.g., Manhattan, Brooklyn).\n",
    "- **Neighborhood**: The specific neighborhood within the borough.\n",
    "- **Latitude**: The latitude coordinate of the listing.\n",
    "- **Longitude**: The longitude coordinate of the listing.\n",
    "- **Room Type**: The type of room being offered (e.g., entire home/apt, private room, shared room).\n",
    "- **Price**: The price per night for the listing.\n",
    "- **Minimum Nights**: The minimum number of nights a guest must stay.\n",
    "- **Number of Reviews**: The total number of reviews for the listing.\n",
    "- **Last Review**: The date of the last review.\n",
    "- **Reviews per Month**: The average number of reviews per month.\n",
    "- **Calculated Host Listings Count**: The total number of listings by the host.\n",
    "- **Availability 365**: The number of days the listing is available in a year.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this analysis, we aim to achieve the following objectives:\n",
    "\n",
    "1. **Data Exploration**: Understand the structure and contents of the dataset through summary statistics and visualizations.\n",
    "2. **Price Analysis**: Analyze the pricing strategies of different types of listings and identify factors influencing prices.\n",
    "3. **Geographical Analysis**: Examine the geographical distribution of listings and identify popular neighborhoods.\n",
    "4. **Review Analysis**: Investigate the review patterns and their correlation with listing popularity and price.\n",
    "5. **Availability Analysis**: Analyze the availability of listings and identify trends related to booking frequency.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJKIFPGLj2qK"
   },
   "source": [
    "# Data preparation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeGhtWB73Nd8"
   },
   "source": [
    "Data preparation - How do we organize the data for modeling?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "aeGhtWB73Nd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/suvo/Documents/MS-USD/AAI510-Machine Learning/AAI510_FinalProject/src\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'evaluation.ModelEvaluator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Add the src directory to the Python path\u001b[39;00m\n\u001b[1;32m     18\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(src_path)\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mModelEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelEvaluator\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mColumnEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ColumnEncoder\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mColumnSelector\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ColumnSelector\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'evaluation.ModelEvaluator'"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add path to src\n",
    "current_dir = os.getcwd()\n",
    "src_path = os.path.join(current_dir, 'src')\n",
    "print(src_path)\n",
    "sys.path.append(src_path)\n",
    "\n",
    "from evaluation.ModelEvaluator import ModelEvaluator\n",
    "from preprocessing.ColumnEncoder import ColumnEncoder\n",
    "from preprocessing.ColumnSelector import ColumnSelector\n",
    "from preprocessing.DataCleaner import DataCleaner\n",
    "from preprocessing.DataImputer import DataImputer\n",
    "from tuners.HistGradientBoostingRegressorTuner import HistGradientBoostingRegressorTuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gmMvygRXj-97"
   },
   "source": [
    "# Feature engineering – data pre-processing – missing values, outliers, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gmMvygRXj-97"
   },
   "outputs": [],
   "source": [
    "print(\"Preprocessing data.\")\n",
    "data_path: str = \"../data/listings-full.csv\"\n",
    "\n",
    "data: pd.DataFrame = pd.read_csv(data_path)\n",
    "data = DataCleaner.perform_base_cleaning(data)\n",
    "data = DataImputer.remove_outliers_iqr(data, [\"price\"])\n",
    "\n",
    "train_data, val_data, test_data = DataCleaner.split_train_val_test(data)\n",
    "\n",
    "train_data = ColumnEncoder.mean_encode_columns(train_data, ColumnSelector.get_categorical_features(train_data), \"price\")\n",
    "val_data = ColumnEncoder.mean_encode_columns(val_data, ColumnSelector.get_categorical_features(val_data), \"price\")\n",
    "test_data = ColumnEncoder.mean_encode_columns(test_data, ColumnSelector.get_categorical_features(test_data), \"price\")\n",
    "\n",
    "train_data = DataImputer.impute_missing_values(train_data, data.columns, SimpleImputer(strategy=\"median\"))\n",
    "val_data = DataImputer.impute_missing_values(val_data, data.columns, SimpleImputer(strategy=\"median\"))\n",
    "\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = DataCleaner.perform_x_y_split(train_data, val_data, test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5cZtDOajvQx"
   },
   "source": [
    "# Data understanding (EDA) – a graphical and non-graphical representation of relationships between the response variable and predictor variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4AMkJsL3KBX"
   },
   "source": [
    "Data understanding - What data do we have/need? Is it clean?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4AMkJsL3KBX"
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "\n",
    "df = pd.read_csv(\"data/listings-full.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4AMkJsL3KBX"
   },
   "outputs": [],
   "source": [
    "Data understanding - What data do we have/need? Is it clean?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4AMkJsL3KBX"
   },
   "outputs": [],
   "source": [
    "Data understanding - What data do we have/need? Is it clean?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4AMkJsL3KBX"
   },
   "outputs": [],
   "source": [
    "Data understanding - What data do we have/need? Is it clean?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4AMkJsL3KBX"
   },
   "outputs": [],
   "source": [
    "Data understanding - What data do we have/need? Is it clean?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wtv-LeM-kBwB"
   },
   "source": [
    "# Feature Selection – how were the features selected based on the data analysis?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qw-0mO7TkG_j"
   },
   "source": [
    "# Modeling – selection, comparison, tuning, and analysis – consider ensembles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DoEX3aoy3Qn-"
   },
   "source": [
    "\n",
    "Modeling - What modeling techniques should we apply?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Boqf4mpXkKc6"
   },
   "source": [
    "# Evaluation – performance measures, results, and conclusions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0DAUFMOh3TE5"
   },
   "source": [
    "Evaluation - Which model best meets the business objectives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32-NFoYNkOTv"
   },
   "source": [
    "# Discussion and conclusions – address the problem statement and recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gha5DOak3WOv"
   },
   "source": [
    "Deployment - How to get the model in production and ensure it works?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4_41USUiryi"
   },
   "source": [
    "# References and Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSFgmYwOixQb"
   },
   "source": [
    "GitHub link: https://github.com/suvoganguli/AAI510_FinalProject\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Tensorflow2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
